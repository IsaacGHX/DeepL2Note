# 总结一下，要想将神经网络的泛化能力最大化，并防止过拟合，最常用的方法如下所述。
#  获取更多或更好的训练数据。
#  找到更好的特征。
#  缩减模型容量。
#  添加权重正则化（用于较小的模型）。
#  添加 dropout。


# 本章总结
#  机器学习模型的目的在于泛化，即在前所未见的输入上表现良好。
# 这看起来不难，但实现起来很难。
#  深度神经网络实现泛化的方式是：学习一个参数化模型，这个模型可以成功地在训练样本之间
# 进行插值——这样的模型学会了训练数据的“潜在流形”。这就是为什么深度学习模型只能理解与训练数据
# 非常接近的输入。
#  机器学习的根本问题是优化与泛化之间的矛盾：为了实现泛化，你必须首先实现对训练数据的良好拟合，
# 但改进模型对训练数据的拟合，在一段时间之后将不可避免地降低泛化能力。
# 深度学习的所有最佳实践都旨在解决这一矛盾。
#  深度学习模型的泛化能力来自于这样一个事实：模型努力逼近数据的潜在流形，
# 从而通过插值来理解新的输入。
#  在开发模型时，能够准确评估模型的泛化能力是非常重要的。你可以使用多种评估方法，
# 包括简单的留出验证、K 折交叉验证，以及带有打乱数据的重复 K 折交叉验证。请记住，
# 要始终保留一个完全独立的测试集用于最终的模型评估，因为可能已经发生了从验证数据到模型的信息泄露。
#  开始构建模型时，你的目标首先是实现一个具有一定泛化能力并且能够过拟合的模型。
# 要做到这一点，最佳做法包括调整学习率和批量大小、利用更好的架构预设、增加模型容量或者仅仅延长训练时间。
#  模型开始过拟合之后，你的目标将转为利用模型正则化来提高泛化能力。
# 你可以缩减模型容量、添加 dropout 或权重正则化，以及使用 EarlyStopping。
# 当然，要想提高模型的泛化能力，首选方法始终是收集更大或更好的数据集。
