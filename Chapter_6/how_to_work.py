# 机器学习的通用工作流程大致分为以下 3 步。
# (1) 定义任务。了解问题所属领域和客户需求背后的业务逻辑。收集数据集，理解数据所代表的含义，
# 并选择衡量任务成功的指标。
# (2) 开发模型。准备数据，使其可以被机器学习模型处理。选择模型评估方法，并确定一个简单基准
# （模型应能够超越这个基准）。训练第一个具有泛化能力并且能够过拟合的模型，
# 然后对模型进行正则化并不断调节，直到获得最佳泛化性能。
# (3) 部署模型。将工作展示给利益相关者，将模型部署到 Web 服务器、移动应用程序、网页或嵌入式设备上，
# 监控模型在真实环境中的性能，并开始收集构建下一代模型所需的数据。


# 6.1定义任务:
# 客户为什么要解决某个问题？
# 能够从解决方案中获得什么价值——你的模型将被如何使用，模型又将如何融入客户的业务流程?
# 什么样的数据是可用的，或是可收集的？
# 哪种类型的机器学习任务与业务问题相关？

# 6.1.1 定义问题
# 定义一个机器学习问题，通常需要与利益相关者进行多次详细讨论。
#  你的输入数据是什么？你要预测什么？
# 只有拥有可用的训练数据，你才能学习预测某件事情。
# 举个例子，只有拥有**可用的影评和**情感标注，你才能学习对影评进行情感分类。
# 因此，数据可用性通常是这一阶段的限制因素。在多数情况下，你需要**自己收集和标注新的数据集。
# 你面对的是什么类型的机器学习任务？
# 是二分类问题、多分类问题、标量回归问题、向量回归问题，还是多分类、多标签问题？
# 是图像分割问题、排序问题，还是聚类、生成式学习或强化学习等其他问题？
# 在某些情况下，机器学习甚至可能不是理解数据的最佳方式，你应该使用其他方法，比如传统的统计分析方法。

#  图片搜索引擎项目是一项多分类、多标签的分类任务。
#  垃圾信息检测项目是一项二分类任务。如果将“攻击性内容”划为一个单独的类别，则它是一项三分类任务。
#  事实证明，对于音乐推荐引擎来说，**矩阵分解（协同过滤）比深度学习的效果更好。
#  信用卡欺诈检测项目是一项二分类任务。
#  点击率预测项目是一项标量回归任务。
#  异常饼干检测项目是一项二分类任务。但这个任务前期还需要一个**目标检测模型，
# 以便从原始图像中正确裁剪出饼干图像。请注意，被称为“异常检测”的机器学习方法并不适用于此任务。
#  从卫星图像中寻找新的考古遗址，这是一项图像相似度排序任务。
# 你需要检索新图像，找出那些与已知考古遗址最相似的图像。
#  现有的解决方案是什么？
# 或许你的客户已经拥有一个人工编写的算法来过滤垃圾信息或检测信用卡欺诈，其中包含很多嵌套的 if 语句。
# 或许目前有人在手动处理以下流程：
# 监控饼干厂的传送带并手动移除异常饼干，
# 或者创建歌曲推荐播放列表并发送给喜欢特定艺术家的用户。
# 你应该知道目前在用的有哪些系统，以及它们是如何工作的。
#  你是否需要处理一些特殊的限制？
# 比如你正在为一个应用程序构建垃圾信息检测系统，而这个应用程序是严格端到端加密的，
# 垃圾信息检测模型需要部署在最终用户的手机上，并且需要在外部数据集上进行训练。
# 饼干过滤模型也许会有延迟限制，因此需要在工厂的嵌入式设备上运行，而不是在远程服务器上运行。
# **你应该全面地了解工作背景。

# 完成对上述问题的调研之后，你应该已经知道你的输入是什么、你的目标是什么，
# 以及这个问题与哪一类机器学习任务相关。要注意你在这一阶段所做的假设。
#  假设**可以根据输入对目标进行预测。
#  假设现有数据（或后续收集的数据）所包含的信息**足以用来学习输入和目标之间的关系。
# 在开发出工作模型之前，这些只是假设，等待验证真假。
# 并不是所有问题都可以用机器学习方法来解决。
# 你收集了包含输入 X 和目标 Y 的许多示例，并不意味着 X 包含足够多的信息来预测 Y。
# 举个例子，如果你想根据某只股票近期历史价格来预测其价格走势，那么不太可能会成功，
# 因为历史价格中没有包含很多可用于预测的信息。


# 6.1.2 收集数据集
# 你已经了解任务的性质，并且知道输入和目标分别是什么，下面就该收集数据了——
# 对于大部分机器学习项目而言，这一步是最费力、最费时、最费钱的。
#  对于图片搜索引擎项目，你首先需要选择分类标签集，比如 10 000 个常见图像类别。
# 然后，你需要根据这个标签集**手动标记用户上传的数十万张图片。
#  对于聊天应用程序的垃圾信息检测项目，因为用户的聊天内容是端到端加密的，
# 所以你无法使用聊天内容来训练模型。你需要获取一个单独的数据集，
# 其中包含上万条未经过滤的社交媒体信息，然后手动将其标记为垃圾信息、攻击性信息或正常信息。
#  对于音乐推荐引擎，你可以直接使用用户的“点赞”数据，无须收集新数据。
# 同样，对于点击率预测项目也是如此，你拥有过去几年里大量的广告点击率记录。
#  对于饼干标记模型，你需要在传送带上方安装摄像头，收集数万张图像，
# 然后需要有人手动标记这些图像。知道如何标记的人目前都在饼干厂上班，但这似乎并不难。
# 你应该能够培训人们来完成这件事。
#  对于卫星图像项目，需要一个由考古学家组成的团队来收集一个数据库，其中包含他们
# 感兴趣的遗址，并且对于每个遗址，都需要找到在不同天气条件下拍摄的卫星图像。
# 为了得到一个好的模型，你需要上千个考古遗址的信息。

# 模型的泛化能力几乎完全来自训练数据的属性，即**数据点的数量、标签的可靠性以及特征的质量。
# 好的数据集是一种值得关注和投资的资产。如果你在一个项目上额外多出 50小时可用的时间，
# 那么最有效的时间分配方式可能是收集更多的数据，而不是尝试逐步改进模型。
# 数据比算法更重要，这一著名观点由谷歌研究人员 2009 年发表的题为“数据不可思议的有效性”的文章
# 提出——这个标题意在致敬 Eugene Wigner 于 1960 年发表的著名文章“数学在自然科学中不可思议的有效性”。
# 这篇文章发表于深度学习流行之前，但值得注意的是，深度学习的兴起让数据变得更加重要。
# 如果你做的是监督学习，那么收集完输入数据（比如图像）之后，
# 你还需要这些输入数据的标注（比如图像的标签），也就是训练模型要预测的目标。
# 有时可以自动获取标注，比如音乐推荐任务或点击率预测任务，但通常需要人工标注数据。
# 这一过程的工作量很大。





